#!/bin/bash
# Morpheus API Gateway - AWS EC2 Setup and Management Script
# This script provides four functionalities:
# 1. Initial EC2 Setup: Complete setup from a fresh EC2 instance
# 2. Service Restart: For code updates without full reinstall
# 3. Manual Gunicorn Start: Direct start without systemd
# 4. Manual Setup Instructions: For reference/troubleshooting

#-----------------------------------------------------
# SECTION 0: Github Auth (Fresh Instance)
#-----------------------------------------------------
# ssh-keygen -t rsa -b 4096 -C "your_email@example.com"
# cat ~/.ssh/id_rsa.pub
# paste the public key into github settings (https://github.com/<username>/<repo>/settings/keys)

#-----------------------------------------------------
# SECTION 1: INITIAL EC2 SETUP (Fresh Instance)
#-----------------------------------------------------
setup_fresh_instance() {
    echo "======================================================"
    echo "Starting Fresh EC2 Instance Setup"
    echo "======================================================"

    # System Updates and Dependencies
    echo "Installing system dependencies..."
    sudo yum update -y
    sudo yum install git gcc make openssl-devel bzip2-devel libffi-devel zlib-devel postgresql-devel postgresql-libs python3.11 python3.11-pip python3.11-devel docker postgresql15 -y

    # Setup Docker
    echo "Setting up Docker..."
    sudo systemctl enable docker
    sudo systemctl start docker
    sudo usermod -a -G docker ec2-user
    sudo curl -L "https://github.com/docker/compose/releases/latest/download/docker-compose-$(uname -s)-$(uname -m)" -o /usr/local/bin/docker-compose
    sudo chmod +x /usr/local/bin/docker-compose

    # Variables
    PROJECT_DIR="/home/ec2-user/morpheus-API"
    VENV_DIR="/home/ec2-user/venv-morpheus"
    SERVICE_USER="ec2-user"

    # Create project directory if it doesn't exist
    echo "Creating project directory at $PROJECT_DIR..."
    sudo mkdir -p $PROJECT_DIR
    if [ ! -d "$PROJECT_DIR" ]; then
        echo "ERROR: Failed to create $PROJECT_DIR directory"
        exit 1
    fi
    sudo chown $SERVICE_USER:$SERVICE_USER $PROJECT_DIR

    # Clean virtual environment if it exists
    sudo rm -rf $VENV_DIR

    # Clone Repository
    echo "Cloning repository..."
    cd $PROJECT_DIR
    
    # Use HTTPS for public repository
    sudo -u $SERVICE_USER git clone --depth 1 -b feat-toolcalling https://github.com/bowtiedbluefin/morpheus-API.git temp_repo
    
    # Check if clone was successful
    if [ ! -d "temp_repo" ]; then
        echo "ERROR: Failed to clone repository."
        echo "Try cloning manually with: git clone https://github.com/bowtiedbluefin/morpheus-API.git"
        echo "Then run this script with the 'restart' option"
        exit 1
    fi
    
    sudo -u $SERVICE_USER cp -r temp_repo/. .
    sudo -u $SERVICE_USER rm -rf temp_repo

    # Setup Python Environment
    echo "Setting up Python virtual environment..."
    sudo -u $SERVICE_USER python3.11 -m venv $VENV_DIR
    source $VENV_DIR/bin/activate
    pip install --upgrade pip

    # Install Dependencies
    echo "Installing Python dependencies..."
    if [ -f "pyproject.toml" ] || [ -f "poetry.lock" ]; then
        pip install poetry
        poetry install --no-root --no-interaction
    elif [ -f "requirements.txt" ]; then
        pip install -r requirements.txt
    else
        echo "No dependency file found. Cannot proceed."
        exit 1
    fi
    pip install gunicorn

    # Configure Environment
    echo "Setting up environment variables..."
    if [ -f .env.example ]; then
        sudo -u $SERVICE_USER cp .env.example .env
        
        # Generate secure keys
        JWT_SECRET=$(openssl rand -hex 32)
        ENCRYPTION_KEY=$(openssl rand -hex 32)

        # Update .env file
        sudo sed -i 's/^POSTGRES_USER=.*/POSTGRES_USER=morpheus_user/' .env
        sudo sed -i 's/^POSTGRES_PASSWORD=.*/POSTGRES_PASSWORD=morpheus_password/' .env
        sudo sed -i 's/^POSTGRES_DB=.*/POSTGRES_DB=morpheus_db/' .env
        sudo sed -i 's|^DATABASE_URL=.*|DATABASE_URL=postgresql+asyncpg://morpheus_user:morpheus_password@localhost:5432/morpheus_db|' .env
        sudo sed -i 's/^REDIS_PASSWORD=.*/REDIS_PASSWORD=your_redis_password/' .env
        sudo sed -i 's|^REDIS_URL=.*|REDIS_URL=redis://:your_redis_password@localhost:6379/0|' .env
        sudo sed -i 's|^PROXY_ROUTER_URL=.*|PROXY_ROUTER_URL=http://localhost:8082|' .env
        sudo sed -i "s/^JWT_SECRET_KEY=.*/JWT_SECRET_KEY=$JWT_SECRET/" .env
        sudo sed -i "s/^MASTER_ENCRYPTION_KEY=.*/MASTER_ENCRYPTION_KEY=$ENCRYPTION_KEY/" .env
        sudo sed -i 's/^ACCESS_TOKEN_EXPIRE_MINUTES=.*/ACCESS_TOKEN_EXPIRE_MINUTES=30/' .env
        sudo sed -i 's/^REFRESH_TOKEN_EXPIRE_DAYS=.*/REFRESH_TOKEN_EXPIRE_DAYS=7/' .env
        sudo sed -i 's/^AUTOMATION_FEATURE_ENABLED=.*/AUTOMATION_FEATURE_ENABLED=true/' .env

        # Contract Settings (TESTNET)
        sudo sed -i 's/^DIAMOND_CONTRACT_ADDRESS=.*/DIAMOND_CONTRACT_ADDRESS=0xb8C55cD613af947E73E262F0d3C54b7211Af16CF/' .env
        sudo sed -i 's/^CONTRACT_ADDRESS=.*/CONTRACT_ADDRESS=0x34a285a1b1c166420df5b6630132542923b5b27e/' .env
        sudo sed -i 's|^BLOCKSCOUT_API_URL=.*|BLOCKSCOUT_API_URL="https://arbitrum-sepolia.blockscout.com/api/v2"|' .env
        sudo sed -i 's/^CHAIN_ID=.*/CHAIN_ID=421614/' .env
        sudo sed -i 's/^ENVIRONMENT=.*/ENVIRONMENT=development/' .env

        # Placeholder for FALLBACK_PRIVATE_KEY
        sudo sed -i 's/^FALLBACK_PRIVATE_KEY=.*/FALLBACK_PRIVATE_KEY=xxxx_REPLACE_THIS_MANUALLY_xxxx/' .env
        echo "WARNING: Update FALLBACK_PRIVATE_KEY in .env manually!"

        sudo chown $SERVICE_USER:$SERVICE_USER .env
        sudo chmod 600 .env
    fi

    # Start Database and Redis
    echo "Starting PostgreSQL and Redis containers..."
    
    # Always create/overwrite docker-compose.yml with the correct settings
    echo "Creating docker-compose.yml file with host networking..."
    cat > docker-compose.yml << 'EOL'
version: '3.8' # Use a more recent version

services:
  db:
    image: postgres:15-alpine
    network_mode: "host" # Use host network for direct localhost access
    volumes:
      - postgres_data:/var/lib/postgresql/data/
    environment:
      POSTGRES_USER: ${POSTGRES_USER:-morpheus_user}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD:-morpheus_password}
      POSTGRES_DB: ${POSTGRES_DB:-morpheus_db}
    # Ports section is not needed with network_mode: host, but doesn't hurt
    ports:
      - "5432:5432"
    restart: always

  redis:
    image: redis:7-alpine
    network_mode: "host" # Use host network for direct localhost access
    command: redis-server --requirepass ${REDIS_PASSWORD:-your_redis_password}
    # Ports section is not needed with network_mode: host, but doesn't hurt
    ports:
      - "6379:6379"
    restart: always

volumes:
  postgres_data:
EOL
    sudo chown $SERVICE_USER:$SERVICE_USER docker-compose.yml
    
    # Stop any existing containers first
    echo "Stopping existing containers (if any)..."
    sudo docker-compose down --remove-orphans || true
    sleep 2
    
    # Start the containers
    echo "Starting containers..."
    sudo docker-compose up -d db redis
    sleep 5
    
    # Verify containers are running
    echo "Verifying containers are running..."
    sudo docker-compose ps
    
    # Wait for the database to be ready
    echo "Waiting for database to start (this may take up to 30 seconds)..."
    for i in {1..6}; do
        echo "Attempt $i: Checking if database is ready on port 5432..."
        # Use docker-compose exec and correct port 5432
        if sudo docker-compose exec db pg_isready -h localhost -p 5432 -U ${POSTGRES_USER:-morpheus_user} -d ${POSTGRES_DB:-morpheus_db} > /dev/null 2>&1; then
            echo "Database is ready!"
            break
        elif [ $i -eq 6 ]; then
            echo "WARNING: Database check timed out. Continuing anyway..."
            echo "Troubleshooting tips:"
            echo "  - Check Docker logs: sudo docker-compose logs db"
            echo "  - Ensure port 5432 is free on the host."
            echo "  - Verify .env variables POSTGRES_USER, POSTGRES_PASSWORD, POSTGRES_DB match docker-compose.yml"
        else
            sleep 5
        fi
    done
    
    # Run Alembic migrations
    echo "Running database migrations..."
    source $VENV_DIR/bin/activate
    export PYTHONPATH=$PROJECT_DIR
    
    # Check alembic.ini file_template format and fix if needed
    echo "Checking alembic.ini file_template format..."
    if grep -q "file_template.*hour.*minute" alembic.ini; then
        echo "Fixing alembic.ini file_template to avoid revision tracking issues..."
        sed -i 's/file_template = %%(year)d_%%(month).2d_%%(day).2d_%%(hour).2d%%(minute).2d_%%(rev)s_%%(slug)s/file_template = %%(year)d_%%(month).2d_%%(day).2d_%%(rev)s_%%(slug)s/' alembic.ini
    fi
    
    # Create fix_alembic.py script for version repair
    echo "Setting up migration fix script..."
    cat > fix_alembic.py << 'EOL'
#!/usr/bin/env python3
import asyncio, os, sys
from sqlalchemy import text
from sqlalchemy.ext.asyncio import create_async_engine, AsyncSession

# Import settings
sys.path.insert(0, os.path.abspath('.'))
from src.core.config import settings

# The correct revision ID from the latest migration
CORRECT_REVISION = '881e615d25ac'

async def fix_alembic_version():
    db_url = os.getenv("DATABASE_URL", str(settings.DATABASE_URL))
    engine = create_async_engine(db_url)
    async with AsyncSession(engine) as session:
        try:
            result = await session.execute(text("SELECT EXISTS (SELECT FROM information_schema.tables WHERE table_name = 'alembic_version')"))
            if result.scalar():
                await session.execute(text(f"UPDATE alembic_version SET version_num = '{CORRECT_REVISION}'"))
            else:
                await session.execute(text("CREATE TABLE alembic_version (version_num VARCHAR(32) PRIMARY KEY)"))
                await session.execute(text(f"INSERT INTO alembic_version VALUES ('{CORRECT_REVISION}')"))
            await session.commit()
            print("Alembic version fixed!")
        except Exception as e:
            print(f"Error: {e}")
            await session.rollback()

if __name__ == "__main__": asyncio.run(fix_alembic_version())
EOL
    chmod +x fix_alembic.py
    
    # Try to run standard migrations first
    echo "Running alembic migrations..."
    python3 fix_alembic.py  # Ensure correct version in table
    
    # Run all migrations
    alembic upgrade head
    if [ $? -ne 0 ]; then
        echo "WARNING: Migration failed, trying to fix..."
        python3 fix_alembic.py
        alembic upgrade head
        # If still failing, try direct table creation as fallback
        if [ $? -ne 0 ]; then
            echo "WARNING: Migration still failing, creating tables directly..."
            # Create direct table creation script
            
            # Ensure PostgreSQL client is installed for direct table creation
            if ! command -v psql &> /dev/null; then
                echo "Installing PostgreSQL client..."
                sudo yum install -y postgresql15
            fi

            # Create direct table creation script
            cat > create_tables.py << 'EOL'
#!/usr/bin/env python3
import asyncio, os, sys
from sqlalchemy import text
from sqlalchemy.ext.asyncio import create_async_engine, AsyncSession

sys.path.insert(0, os.path.abspath('.'))
from src.core.config import settings

async def create_tables():
    db_url = os.getenv("DATABASE_URL", str(settings.DATABASE_URL))
    engine = create_async_engine(db_url)
    async with AsyncSession(engine) as session:
        try:
            # Check if sessions table exists
            result = await session.execute(text(
                "SELECT EXISTS (SELECT FROM information_schema.tables WHERE table_name = 'sessions')"
            ))
            sessions_exists = result.scalar()
            
            if not sessions_exists:
                print("Creating sessions table...")
                await session.execute(text("""
                CREATE TABLE sessions (
                    id VARCHAR NOT NULL, 
                    user_id INTEGER, 
                    api_key_id INTEGER, 
                    model VARCHAR NOT NULL, 
                    type VARCHAR NOT NULL, 
                    created_at TIMESTAMP WITHOUT TIME ZONE, 
                    expires_at TIMESTAMP WITHOUT TIME ZONE NOT NULL, 
                    is_active BOOLEAN, 
                    PRIMARY KEY (id), 
                    FOREIGN KEY(api_key_id) REFERENCES api_keys (id), 
                    FOREIGN KEY(user_id) REFERENCES users (id)
                )
                """))
                
                await session.execute(text(
                    "CREATE INDEX ix_sessions_api_key_id ON sessions (api_key_id)"
                ))
                
                await session.execute(text(
                    "CREATE INDEX ix_sessions_is_active ON sessions (is_active)"
                ))
                
                await session.execute(text("""
                CREATE UNIQUE INDEX sessions_active_api_key_unique 
                ON sessions (api_key_id, is_active)
                WHERE is_active IS true
                """))
                
                print("Sessions table created successfully")
            
            # Check if delegations table exists
            result = await session.execute(text(
                "SELECT EXISTS (SELECT FROM information_schema.tables WHERE table_name = 'delegations')"
            ))
            delegations_exists = result.scalar()
            
            if not delegations_exists:
                print("Creating delegations table...")
                await session.execute(text("""
                CREATE TABLE delegations (
                    id SERIAL NOT NULL, 
                    user_id INTEGER NOT NULL, 
                    delegate_address VARCHAR NOT NULL, 
                    signed_delegation_data TEXT NOT NULL, 
                    expiry TIMESTAMP WITHOUT TIME ZONE, 
                    created_at TIMESTAMP WITH TIME ZONE DEFAULT now(), 
                    is_active BOOLEAN, 
                    PRIMARY KEY (id), 
                    FOREIGN KEY(user_id) REFERENCES users (id)
                )
                """))
                
                await session.execute(text(
                    "CREATE INDEX ix_delegations_delegate_address ON delegations (delegate_address)"
                ))
                
                await session.execute(text(
                    "CREATE INDEX ix_delegations_id ON delegations (id)"
                ))
                
                await session.execute(text(
                    "CREATE INDEX ix_delegations_is_active ON delegations (is_active)"
                ))
                
                await session.execute(text(
                    "CREATE INDEX ix_delegations_user_id ON delegations (user_id)"
                ))
                
                print("Delegations table created successfully")
            
            await session.commit()
            print("Tables verified or created successfully")
        except Exception as e:
            print(f"ERROR: {e}")
            await session.rollback()

if __name__ == "__main__": asyncio.run(create_tables())
EOL
            chmod +x create_tables.py
            python3 create_tables.py
        fi
    fi
    
    # Verify final state
    echo "Verifying final database state..."
    python3 -c "
import asyncio, os, sys
from sqlalchemy import text
from sqlalchemy.ext.asyncio import create_async_engine, AsyncSession
from alembic.script import ScriptDirectory
from alembic.config import Config

sys.path.insert(0, os.path.abspath('.'))
from src.core.config import settings

async def verify_migrations():
    db_url = os.getenv('DATABASE_URL', str(settings.DATABASE_URL))
    engine = create_async_engine(db_url)
    
    # Get expected revision
    config = Config('alembic.ini')
    script = ScriptDirectory.from_config(config)
    head_revision = script.get_current_head()
    print(f'Expected revision: {head_revision}')
    
    async with AsyncSession(engine) as session:
        # Check current revision
        result = await session.execute(text(\"SELECT version_num FROM alembic_version\"))
        current_revision = result.scalar_one_or_none()
        print(f'Current revision: {current_revision}')
        
        # Check sessions table
        result = await session.execute(text(\"SELECT EXISTS (SELECT FROM information_schema.tables WHERE table_name = 'sessions')\"))
        sessions_exists = result.scalar()
        print(f'Sessions table exists: {sessions_exists}')
        
        # Check delegations table
        result = await session.execute(text(\"SELECT EXISTS (SELECT FROM information_schema.tables WHERE table_name = 'delegations')\"))
        delegations_exists = result.scalar()
        print(f'Delegations table exists: {delegations_exists}')

asyncio.run(verify_migrations())
"
    
    # Add the manage_migrations.sh utility script
    echo "Creating migration management script..."
    cat > manage_migrations.sh << 'EOL'
#!/bin/bash
# Migration management script for Morpheus API

set -e  # Exit on error

# Colors for output
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
NC='\033[0m' # No Color

# Banner
echo -e "${BLUE}==============================${NC}"
echo -e "${BLUE}Morpheus API Migration Manager${NC}"
echo -e "${BLUE}==============================${NC}"

# Function to display usage information
function show_usage {
    echo -e "${YELLOW}Usage:${NC}"
    echo -e "  $0 ${GREEN}create${NC} <description> - Create a new migration"
    echo -e "  $0 ${GREEN}upgrade${NC} - Apply all pending migrations"
    echo -e "  $0 ${GREEN}downgrade${NC} - Downgrade to previous migration"
    echo -e "  $0 ${GREEN}current${NC} - Show current migration version"
    echo -e "  $0 ${GREEN}history${NC} - Show migration history"
    echo -e "  $0 ${GREEN}fix${NC} - Fix alembic versioning (if problems occur)"
    echo -e "  $0 ${GREEN}verify${NC} - Verify migration status"
}

# Process commands
case "$1" in
    create)
        if [ -z "$2" ]; then
            echo -e "${RED}Error: Missing migration description${NC}"
            echo -e "Example: $0 create add_user_table"
            exit 1
        fi
        echo -e "${BLUE}Creating new migration: ${YELLOW}$2${NC}"
        alembic revision --autogenerate -m "$2"
        echo -e "${GREEN}Migration created successfully!${NC}"
        ;;
    upgrade)
        echo -e "${BLUE}Applying all pending migrations...${NC}"
        alembic upgrade head
        echo -e "${GREEN}Migrations applied successfully!${NC}"
        ;;
    downgrade)
        echo -e "${YELLOW}WARNING: Downgrading database to previous revision${NC}"
        read -p "Are you sure you want to continue? (y/n) " -n 1 -r
        echo
        if [[ $REPLY =~ ^[Yy]$ ]]; then
            alembic downgrade -1
            echo -e "${GREEN}Database downgraded successfully!${NC}"
        else
            echo -e "${BLUE}Downgrade cancelled.${NC}"
        fi
        ;;
    current)
        echo -e "${BLUE}Current database revision:${NC}"
        alembic current
        ;;
    history)
        echo -e "${BLUE}Migration history:${NC}"
        alembic history
        ;;
    fix)
        echo -e "${YELLOW}Attempting to fix alembic versioning...${NC}"
        python3 fix_alembic.py
        echo -e "${GREEN}Attempting to apply migrations...${NC}"
        alembic upgrade head
        ;;
    verify)
        echo -e "${BLUE}Verifying database migration status...${NC}"
        python3 -c "
import asyncio, os, sys
from sqlalchemy import text
from sqlalchemy.ext.asyncio import create_async_engine, AsyncSession
from alembic.script import ScriptDirectory
from alembic.config import Config

sys.path.insert(0, os.path.abspath('.'))

async def verify_migrations():
    from src.core.config import settings
    
    db_url = os.getenv('DATABASE_URL', str(settings.DATABASE_URL))
    print(f'Connecting to database: {db_url}')
    
    config = Config('alembic.ini')
    script = ScriptDirectory.from_config(config)
    head_revision = script.get_current_head()
    print(f'Expected revision (head): {head_revision}')
    
    engine = create_async_engine(db_url)
    async with AsyncSession(engine) as session:
        result = await session.execute(text(\"SELECT EXISTS (SELECT FROM information_schema.tables WHERE table_name = 'alembic_version')\"))
        table_exists = result.scalar()
        
        if not table_exists:
            print('ERROR: alembic_version table does not exist!')
            print('Database has not been initialized. Run: ./manage_migrations.sh upgrade')
            return False
            
        result = await session.execute(text(\"SELECT version_num FROM alembic_version\"))
        current_revision = result.scalar_one_or_none()
        print(f'Current revision: {current_revision}')
        
        if current_revision != head_revision:
            print('ERROR: Database is not up to date!')
            print('Run: ./manage_migrations.sh upgrade')
            return False
            
        # Check sessions table
        result = await session.execute(text(\"SELECT EXISTS (SELECT FROM information_schema.tables WHERE table_name = 'sessions')\"))
        sessions_exists = result.scalar()
        
        if not sessions_exists:
            print('ERROR: Sessions table does not exist despite migrations being up to date!')
            print('Run: ./manage_migrations.sh fix')
            return False
            
        print('Database schema is up to date!')
        return True

asyncio.run(verify_migrations())
"
        ;;
    *)
        echo -e "${RED}Error: Unknown command '$1'${NC}"
        show_usage
        exit 1
        ;;
esac
EOL
    chmod +x manage_migrations.sh
    
    # List of migrations in order
    MIGRATIONS=(
        "d4ae65008d6d"  # create initial tables
        "69491a79cfd0"  # add is_active to user model
        "3ec3925c8904"  # add name field to APIKey model
        "7c29c35fc9bc"  # add user sessions table
        "fix_session_constraints"
        "d00825f2a89a"  # add delegation table and user automation settings
        "881e615d25ac"  #consolidate session model
    )
    
    # Run migrations one by one
    for migration in "${MIGRATIONS[@]}"; do
        echo "Running migration: $migration"
        alembic upgrade $migration
        if [ $? -ne 0 ]; then
            echo "WARNING: Migration $migration failed. Attempting to continue..."
            # If it's the delegation table migration that failed, try to create user_automation_settings directly
            if [ "$migration" = "d00825f2a89a" ]; then
                echo "Creating user_automation_settings table directly..."
                # Install PostgreSQL client if not available
                if ! command -v psql &> /dev/null; then
                    echo "Installing PostgreSQL client..."
                    sudo yum install -y postgresql15
                fi
                PGPASSWORD=morpheus_password psql -U morpheus_user -d morpheus_db -p 5432 -h localhost << EOF
CREATE TABLE IF NOT EXISTS user_automation_settings (
    id SERIAL PRIMARY KEY,
    user_id INTEGER UNIQUE REFERENCES users(id),
    is_enabled BOOLEAN,
    session_duration INTEGER,
    created_at TIMESTAMP,
    updated_at TIMESTAMP
);
CREATE INDEX IF NOT EXISTS ix_user_automation_settings_id ON user_automation_settings (id);
EOF
            fi
        fi
    done

    # Verify final state
    alembic current
    if [ $? -ne 0 ]; then
        echo "ERROR: Database migration verification failed. Please check the logs."
        exit 1
    fi

    # Setup systemd service
    echo "Setting up systemd service..."
    setup_systemd_service

    echo "======================================================"
    echo "Initial Setup Complete!"
    echo "IMPORTANT: Update FALLBACK_PRIVATE_KEY in $PROJECT_DIR/.env"
    echo "Check status: sudo systemctl status morpheus-api"
    echo "Check logs: sudo journalctl -u morpheus-api -f"
    echo "======================================================"
}

#-----------------------------------------------------
# SECTION 2: SERVICE RESTART (For Code Updates)
#-----------------------------------------------------
restart_service() {
    echo "======================================================"
    echo "Restarting Morpheus API Service"
    echo "======================================================"

    PROJECT_DIR="/home/ec2-user/morpheus-API"
    VENV_DIR="/home/ec2-user/venv-morpheus"
    cd $PROJECT_DIR

    echo "Pulling latest changes..."
    git pull

    echo "Running database migrations..."
    source $VENV_DIR/bin/activate
    export PYTHONPATH=$PROJECT_DIR
    
    # Check if our migration utility scripts exist
    if [ -f "fix_alembic.py" ] && [ -f "manage_migrations.sh" ]; then
        echo "Using migration management tools..."
        chmod +x manage_migrations.sh
        ./manage_migrations.sh verify
        
        # If verification fails, try to fix and upgrade
        if [ $? -ne 0 ]; then
            echo "Migration verification failed, attempting to fix..."
            ./manage_migrations.sh fix
            ./manage_migrations.sh verify
        fi
    else
        echo "Migration tools not found, running standard upgrade..."
        alembic upgrade head
        if [ $? -ne 0 ]; then
            echo "ERROR: Database migration failed. Please check the logs."
            exit 1
        fi
    fi

    echo "Restarting services..."
    sudo docker-compose restart db redis
    sleep 5 # Wait for containers to restart

    echo "Restarting API service..."
    sudo systemctl restart morpheus-api

    echo "Service restart complete. Checking status..."
    sudo systemctl status morpheus-api --no-pager
    echo "Check logs with: sudo journalctl -u morpheus-api -f"
}

#-----------------------------------------------------
# SECTION 3: MANUAL GUNICORN START
#-----------------------------------------------------
manual_start() {
    echo "======================================================"
    echo "Starting Morpheus API Manually with Gunicorn"
    echo "======================================================"

    PROJECT_DIR="/home/ec2-user/morpheus-API"
    VENV_DIR="/home/ec2-user/venv-morpheus"

    # Find main application file
    if [ -f "$PROJECT_DIR/src/main.py" ]; then
        UVICORN_MODULE_PATH="src.main"
    elif [ -f "$PROJECT_DIR/app/main.py" ]; then
        UVICORN_MODULE_PATH="app.main"
    elif [ -f "$PROJECT_DIR/main.py" ]; then
        UVICORN_MODULE_PATH="main"
    else
        echo "ERROR: Could not find main.py"
        exit 1
    fi

    cd $PROJECT_DIR
    source $VENV_DIR/bin/activate

    echo "Starting Gunicorn..."
    echo "Logs will appear below. Press Ctrl+C to stop."
    echo "To run in background, use: nohup ./awsonboard manual-start &"
    
    # Run Gunicorn in the foreground
    PYTHONPATH=$PROJECT_DIR gunicorn $UVICORN_MODULE_PATH:app \
        --workers 4 \
        --worker-class uvicorn.workers.UvicornWorker \
        --bind 0.0.0.0:8000 \
        --access-logfile - \
        --error-logfile -
}

#-----------------------------------------------------
# SECTION 4: MANUAL SETUP INSTRUCTIONS
#-----------------------------------------------------
show_manual_instructions() {
    cat << 'EOL'
====================================================
MANUAL SETUP INSTRUCTIONS
====================================================

If you need to set up components manually or troubleshoot:

1. System Dependencies:
   sudo yum update -y
   sudo yum install git gcc make openssl-devel bzip2-devel libffi-devel zlib-devel postgresql-devel postgresql-libs python3.11 python3.11-pip python3.11-devel docker -y

2. Docker Setup:
   sudo systemctl enable docker
   sudo systemctl start docker
   sudo usermod -a -G docker ec2-user
   # Install Docker Compose
   sudo curl -L "https://github.com/docker/compose/releases/latest/download/docker-compose-$(uname -s)-$(uname -m)" -o /usr/local/bin/docker-compose
   sudo chmod +x /usr/local/bin/docker-compose

3. Python Environment:
   python3.11 -m venv ~/venv-morpheus
   source ~/venv-morpheus/bin/activate
   pip install --upgrade pip
   pip install poetry
   poetry install
   # Or: pip install -r requirements.txt

4. Database/Redis (Docker):
   cd ~/morpheus-API
   # Update docker-compose.yml for host networking
   sed -i 's/networks:/network_mode: "host"/' docker-compose.yml
   sed -i '/morpheus_net:/,+2d' docker-compose.yml
   docker-compose up -d db redis

5. Database Migrations:
   source ~/venv-morpheus/bin/activate
   export PYTHONPATH=~/morpheus-API
   cd ~/morpheus-API
   alembic upgrade head
   # If migration fails:
   # alembic stamp head
   # alembic upgrade head

6. Environment Variables:
   cp .env.example .env
   # Edit .env with your settings, ensuring to use localhost for services:
   # DATABASE_URL=postgresql+asyncpg://user:pass@localhost:5432/db <-- Use port 5432
   # REDIS_URL=redis://:pass@localhost:6379/0
   # PROXY_ROUTER_URL=http://localhost:8082
   nano .env

7. Run Application:
   # Direct with uvicorn:
   uvicorn src.main:app --host 0.0.0.0 --port 8000
   # Or with gunicorn:
   gunicorn -k uvicorn.workers.UvicornWorker -w 4 -b 0.0.0.0:8000 src.main:app

8. Systemd Service:
   sudo nano /etc/systemd/system/morpheus-api.service
   sudo systemctl daemon-reload
   sudo systemctl enable morpheus-api
   sudo systemctl start morpheus-api

Common Commands:
- Check service status: sudo systemctl status morpheus-api
- View logs: sudo journalctl -u morpheus-api -f
- Restart service: sudo systemctl restart morpheus-api
- Check Docker containers: docker-compose ps
- View Docker logs: docker-compose logs db redis
====================================================
EOL
}

#-----------------------------------------------------
# SECTION 5: ERROR RECOVERY
#-----------------------------------------------------
recovery_procedure() {
    echo "======================================================"
    echo "Running Recovery Procedure"
    echo "======================================================"

    PROJECT_DIR="/home/ec2-user/morpheus-API"
    VENV_DIR="/home/ec2-user/venv-morpheus"
    cd $PROJECT_DIR
    source $VENV_DIR/bin/activate
    export PYTHONPATH=$PROJECT_DIR

    echo "1. Stopping all services..."
    sudo systemctl stop morpheus-api
    sudo docker-compose down

    echo "2. Waiting for all processes to terminate..."
    sleep 5

    echo "3. Starting database and Redis..."
    sudo docker-compose up -d db redis
    sleep 10  # Give DB time to start

    echo "4. Checking and repairing database schema..."
    # Check if our migration repair tools exist
    if [ -f "fix_alembic.py" ] && [ -f "create_tables.py" ]; then
        echo "Using database repair tools..."
        python3 fix_alembic.py
        alembic upgrade head
        # If still failing, create tables directly
        if [ $? -ne 0 ]; then
            echo "WARNING: Migration still failing, creating tables directly..."
            # Create direct table creation script
            
            # Ensure PostgreSQL client is installed for direct table creation
            if ! command -v psql &> /dev/null; then
                echo "Installing PostgreSQL client..."
                sudo yum install -y postgresql15
            fi

            # Create direct table creation script
            cat > create_tables.py << 'EOL'
#!/usr/bin/env python3
import asyncio, os, sys
from sqlalchemy import text
from sqlalchemy.ext.asyncio import create_async_engine, AsyncSession

sys.path.insert(0, os.path.abspath('.'))
from src.core.config import settings

async def create_tables():
    db_url = os.getenv("DATABASE_URL", str(settings.DATABASE_URL))
    engine = create_async_engine(db_url)
    async with AsyncSession(engine) as session:
        try:
            # Check if sessions table exists
            result = await session.execute(text(
                "SELECT EXISTS (SELECT FROM information_schema.tables WHERE table_name = 'sessions')"
            ))
            sessions_exists = result.scalar()
            
            if not sessions_exists:
                print("Creating sessions table...")
                await session.execute(text("""
                CREATE TABLE sessions (
                    id VARCHAR NOT NULL, 
                    user_id INTEGER, 
                    api_key_id INTEGER, 
                    model VARCHAR NOT NULL, 
                    type VARCHAR NOT NULL, 
                    created_at TIMESTAMP WITHOUT TIME ZONE, 
                    expires_at TIMESTAMP WITHOUT TIME ZONE NOT NULL, 
                    is_active BOOLEAN, 
                    PRIMARY KEY (id), 
                    FOREIGN KEY(api_key_id) REFERENCES api_keys (id), 
                    FOREIGN KEY(user_id) REFERENCES users (id)
                )
                """))
                
                await session.execute(text(
                    "CREATE INDEX ix_sessions_api_key_id ON sessions (api_key_id)"
                ))
                
                await session.execute(text(
                    "CREATE INDEX ix_sessions_is_active ON sessions (is_active)"
                ))
                
                await session.execute(text("""
                CREATE UNIQUE INDEX sessions_active_api_key_unique 
                ON sessions (api_key_id, is_active)
                WHERE is_active IS true
                """))
                
                print("Sessions table created successfully")
            
            # Check if delegations table exists
            result = await session.execute(text(
                "SELECT EXISTS (SELECT FROM information_schema.tables WHERE table_name = 'delegations')"
            ))
            delegations_exists = result.scalar()
            
            if not delegations_exists:
                print("Creating delegations table...")
                await session.execute(text("""
                CREATE TABLE delegations (
                    id SERIAL NOT NULL, 
                    user_id INTEGER NOT NULL, 
                    delegate_address VARCHAR NOT NULL, 
                    signed_delegation_data TEXT NOT NULL, 
                    expiry TIMESTAMP WITHOUT TIME ZONE, 
                    created_at TIMESTAMP WITH TIME ZONE DEFAULT now(), 
                    is_active BOOLEAN, 
                    PRIMARY KEY (id), 
                    FOREIGN KEY(user_id) REFERENCES users (id)
                )
                """))
                
                await session.execute(text(
                    "CREATE INDEX ix_delegations_delegate_address ON delegations (delegate_address)"
                ))
                
                await session.execute(text(
                    "CREATE INDEX ix_delegations_id ON delegations (id)"
                ))
                
                await session.execute(text(
                    "CREATE INDEX ix_delegations_is_active ON delegations (is_active)"
                ))
                
                await session.execute(text(
                    "CREATE INDEX ix_delegations_user_id ON delegations (user_id)"
                ))
                
                print("Delegations table created successfully")
            
            await session.commit()
            print("Tables verified or created successfully")
        except Exception as e:
            print(f"ERROR: {e}")
            await session.rollback()

if __name__ == "__main__": asyncio.run(create_tables())
EOL
            chmod +x create_tables.py
            python3 create_tables.py
        fi
    fi

    echo "5. Checking for orphaned sessions in the database..."
    python3 -c "
import asyncio, os, sys
from sqlalchemy import text
from sqlalchemy.ext.asyncio import create_async_engine, AsyncSession

sys.path.insert(0, os.path.abspath('.'))
from src.core.config import settings

async def cleanup_orphaned_sessions():
    db_url = os.getenv('DATABASE_URL', str(settings.DATABASE_URL))
    engine = create_async_engine(db_url)
    
    async with AsyncSession(engine) as session:
        # Check if sessions table exists
        result = await session.execute(text(\"SELECT EXISTS (SELECT FROM information_schema.tables WHERE table_name = 'sessions')\"))
        if not result.scalar():
            print('Sessions table does not exist, skipping cleanup')
            return
            
        # Deactivate all sessions (mark as inactive)
        try:
            print('Marking all sessions as inactive...')
            result = await session.execute(text(\"UPDATE sessions SET is_active = false\"))
            await session.commit()
            print(f'Successfully deactivated all sessions')
        except Exception as e:
            print(f'Error deactivating sessions: {e}')
            await session.rollback()

asyncio.run(cleanup_orphaned_sessions())
"

    echo "6. Starting up the application..."
    sudo systemctl start morpheus-api
    sleep 5

    echo "7. Checking application status..."
    sudo systemctl status morpheus-api --no-pager

    echo "Recovery procedure complete."
    echo "If problems persist, please check the application logs:"
    echo "  sudo journalctl -u morpheus-api -f"
}

#-----------------------------------------------------
# Helper Functions
#-----------------------------------------------------
setup_systemd_service() {
    # Find main application file
    if [ -f "$PROJECT_DIR/src/main.py" ]; then
        UVICORN_MODULE_PATH="src.main"
    elif [ -f "$PROJECT_DIR/app/main.py" ]; then
        UVICORN_MODULE_PATH="app.main"
    elif [ -f "$PROJECT_DIR/main.py" ]; then
        UVICORN_MODULE_PATH="main"
    else
        echo "ERROR: Could not find main.py"
        exit 1
    fi

    # Create systemd service file
    sudo bash -c "cat > /etc/systemd/system/morpheus-api.service" << EOL
[Unit]
Description=Morpheus API Gateway (Gunicorn)
After=network.target docker.service
Requires=docker.service

[Service]
User=$SERVICE_USER
Group=$(id -gn $SERVICE_USER)
WorkingDirectory=$PROJECT_DIR
Environment="PATH=$VENV_DIR/bin"
Environment="PYTHONPATH=$PROJECT_DIR"
ExecStart=$VENV_DIR/bin/gunicorn $UVICORN_MODULE_PATH:app \\
    --workers 4 \\
    --worker-class uvicorn.workers.UvicornWorker \\
    --bind 0.0.0.0:8000
Restart=always
RestartSec=5
StandardOutput=append:/var/log/morpheus-api.log
StandardError=append:/var/log/morpheus-api.log

[Install]
WantedBy=multi-user.target
EOL

    # Enable and start service
    sudo systemctl daemon-reload
    sudo systemctl enable morpheus-api
}

#-----------------------------------------------------
# Main Script Logic
#-----------------------------------------------------
case "$1" in
    "setup")
        setup_fresh_instance
        ;;
    "restart")
        restart_service
        ;;
    "manual-start")
        manual_start
        ;;
    "manual")
        show_manual_instructions
        ;;
    "recovery")
        recovery_procedure
        ;;
    *)
        echo "Usage: $0 {setup|restart|manual-start|manual|recovery}"
        echo "  setup        - Set up a fresh EC2 instance"
        echo "  restart      - Restart services after code update"
        echo "  manual-start - Start the API manually with Gunicorn"
        echo "  manual       - Show manual setup instructions"
        echo "  recovery     - Run the recovery procedure"
        exit 1
        ;;
esac 